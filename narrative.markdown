# Tunable Consistency in Riak

Consistency is an overloaded word. In RDBMS's consistency refers to maintaining certain contraints with regard to relational algebra. In distributed shared memory systems, consistency models describe the visibility and ordering of data across nodes. Practically, this means that consistency models explain what happens when latency is high and failures occur. One of the realities of distributed systems is that we must make tradeoffs. If we could offer strong consistency and high availibility, Riak wouldn't exist. To achieve availability guarentees we often use eventual consistency. Many systems already in your infrastructure work in an eventually consistent model. DNS, web caches and asynchronous replication all fit into this category. These examples tend to have temporal knobs for controlling consistency. DNS has TTL. Web cache's have an expiration time. These tools are used when you want to take control of consistency. Instead of walltime, Riak uses logical time to help resolve inconsistencies. Logical time can (but not always) determine the order of events in a distributed system when walltime cannot be trusted (hint: it never can). Furthermore, Riak lets you tune how many actors in your cluster must participate in storing or retrieving data. Rather than being content with, "this data will should be more than 10 seconds old", we can take command our consistency, down to the request level. Riak gives you quite a few knobs to tune consistency, the most commond of which are N, R and W. N is the number of replicas of a piece of data will be in your cluster. Replicas can be used for high availibility and read-performance. R and W are number less than or equal to N. R determines the number of actors that must respond to a query before it is considered succesful and returned to the user. If R=N, you are assured that you're reading every version of a document. If W=N, the write is not returned until all replicas have seen the new value. Furthermore, if R+W > N, we are also assured that when we read a value back, we see every value that was written at the time-of-read. With just these three parameters we can drastically change Riak's performance and consistency characteristics. The value for N can be set as both a database default, and a per-bucket default. R and W can be set globally for the database, per-bucket, or even per request. Even though Riak is an eventually consistent database, we can ensure strong consistency any time we need it. If we're going to be making tradeoffs between availability and consistency, we might as well have fine-grained control over them.

When the cluster is running without any down-ed nodes, there are N nodes responsible for dealing with replicas for a piece of data. The nodes are called primaries. When one of these nodes is done, another can act in its place. For example, if nodes {A, B, C} are the primaries for a particular key, we can imagine that C might be unreachable. If we set W=N (3 in this case), our write can still succeed if another node fills in for C, D in our example. Later, when we do a read, if node C is still down, the cluster will know to attempt a read from D. This is an important feature, but sometimes you don't want to treat the fallback nodes the same way you would the primaries. Riak gives you two more tuning parameters, PW and RW. These values are like W and R, but are only concerned with the primary vnodes for a request. 